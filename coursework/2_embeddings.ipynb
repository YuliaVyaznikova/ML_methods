{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0125fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a820a",
   "metadata": {},
   "source": [
    "Определяем функции для обучения одной эпохи, оценки модели (с общей и per-class accuracy) и полного цикла обучения с сохранением лучших весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7083de5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE=cpu | 32x32: train=10000, test=2000\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DATA_ROOT = 'C:\\\\IMPORTANT\\\\NSU\\\\3\\\\ML\\\\course_work\\\\.data_cifar10'\n",
    "\n",
    "DOWNLOAD = True\n",
    "cifar10_path = os.path.join(DATA_ROOT, 'cifar-10-batches-py')\n",
    "if os.path.exists(cifar10_path):\n",
    "    DOWNLOAD = False\n",
    "\n",
    "train_tf_32 = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "test_tf_32 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "train_ds_32 = torchvision.datasets.CIFAR10(root=DATA_ROOT, train=True, transform=train_tf_32, download=DOWNLOAD)\n",
    "test_ds_32  = torchvision.datasets.CIFAR10(root=DATA_ROOT, train=False, transform=test_tf_32, download=DOWNLOAD)\n",
    "\n",
    "SUBSET_TRAIN = 10000\n",
    "SUBSET_TEST  = 2000\n",
    "\n",
    "def make_subset(ds, n=None, seed=SEED):\n",
    "    if n is None or n >= len(ds):\n",
    "        return ds\n",
    "    idx = np.random.RandomState(seed).choice(len(ds), size=n, replace=False)\n",
    "    return Subset(ds, idx)\n",
    "\n",
    "train_ds_32_q = make_subset(train_ds_32, SUBSET_TRAIN)\n",
    "test_ds_32_q  = make_subset(test_ds_32,  SUBSET_TEST)\n",
    "\n",
    "BATCH_SIZE = 128 if DEVICE.type == 'cuda' else 64\n",
    "\n",
    "train_ld_32 = DataLoader(train_ds_32_q, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_ld_32  = DataLoader(test_ds_32_q,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "print(f'DEVICE={DEVICE.type} | 32x32: train={len(train_ds_32_q)}, test={len(test_ds_32_q)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed963ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for images, targets in loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running += loss.item()\n",
    "    return running / max(1, len(loader))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, num_classes=10):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    per_class_correct = np.zeros(num_classes, dtype=np.int64)\n",
    "    per_class_total = np.zeros(num_classes, dtype=np.int64)\n",
    "    for images, targets in loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        logits = model(images)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "        t_np = targets.cpu().numpy()\n",
    "        p_np = preds.cpu().numpy()\n",
    "        for t, p in zip(t_np, p_np):\n",
    "            per_class_total[t] += 1\n",
    "            per_class_correct[t] += int(t == p)\n",
    "    acc = correct / max(1, total)\n",
    "    per_class_acc = (per_class_correct / np.maximum(1, per_class_total)).tolist()\n",
    "    return acc, per_class_acc\n",
    "\n",
    "def fit_model(model, train_loader, val_loader, epochs=5, lr=1e-3, device=torch.device('cpu'), name='model', num_classes=10):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    best_path = f'{name}_best.pth'\n",
    "    last_path = f'{name}_last.pth'\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        t0 = time.time()\n",
    "        tr_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_acc, _ = evaluate(model, val_loader, device, num_classes=num_classes)\n",
    "        dt = time.time() - t0\n",
    "        print(f'Epoch {epoch}/{epochs} | train_loss={tr_loss:.4f} | val_acc={val_acc:.4f} | {int(dt)}s')\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "\n",
    "        torch.save(model.state_dict(), last_path)\n",
    "\n",
    "    best_model = type(model)()\n",
    "    if hasattr(best_model, 'classifier') or hasattr(best_model, 'features'):\n",
    "        try:\n",
    "            best_model = type(model)(num_classes=num_classes)\n",
    "        except:\n",
    "            pass\n",
    "    best_model = best_model.to(device)\n",
    "    best_model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "    final_acc, per_class_acc = evaluate(best_model, val_loader, device, num_classes=num_classes)\n",
    "    print(f'Best val_acc(saved)={best_acc:.4f} | Reloaded val_acc={final_acc:.4f}')\n",
    "    print(f'Weights saved: best -> {best_path}, last -> {last_path}')\n",
    "    return best_path, last_path, final_acc, per_class_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf1fd0",
   "metadata": {},
   "source": [
    "Используем простой сверточный классификатор под 32×32 (несколько блоков conv–relu–maxpool + полносвязная голова). Обучаем модель напрямую на изображениях без промежуточных признаков, сохраняем лучшие веса, печатаем accuracy по классам\n",
    "\n",
    "На cpu учимся около 11 минут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a146c44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | train_loss=1.9303 | val_acc=0.4135 | 11s\n",
      "Epoch 2/50 | train_loss=1.6213 | val_acc=0.4630 | 11s\n",
      "Epoch 3/50 | train_loss=1.4847 | val_acc=0.4915 | 11s\n",
      "Epoch 4/50 | train_loss=1.3848 | val_acc=0.5445 | 11s\n",
      "Epoch 5/50 | train_loss=1.2894 | val_acc=0.5955 | 12s\n",
      "Epoch 6/50 | train_loss=1.2088 | val_acc=0.6015 | 13s\n",
      "Epoch 7/50 | train_loss=1.1245 | val_acc=0.6370 | 13s\n",
      "Epoch 8/50 | train_loss=1.0775 | val_acc=0.6395 | 13s\n",
      "Epoch 9/50 | train_loss=1.0334 | val_acc=0.6655 | 13s\n",
      "Epoch 10/50 | train_loss=0.9726 | val_acc=0.6700 | 13s\n",
      "Epoch 11/50 | train_loss=0.9500 | val_acc=0.6920 | 13s\n",
      "Epoch 12/50 | train_loss=0.8890 | val_acc=0.6965 | 13s\n",
      "Epoch 13/50 | train_loss=0.8741 | val_acc=0.6975 | 13s\n",
      "Epoch 14/50 | train_loss=0.8143 | val_acc=0.7040 | 13s\n",
      "Epoch 15/50 | train_loss=0.8213 | val_acc=0.7155 | 13s\n",
      "Epoch 16/50 | train_loss=0.7807 | val_acc=0.7185 | 13s\n",
      "Epoch 17/50 | train_loss=0.7499 | val_acc=0.7335 | 12s\n",
      "Epoch 18/50 | train_loss=0.7395 | val_acc=0.7215 | 13s\n",
      "Epoch 19/50 | train_loss=0.7245 | val_acc=0.7315 | 13s\n",
      "Epoch 20/50 | train_loss=0.6963 | val_acc=0.7350 | 13s\n",
      "Epoch 21/50 | train_loss=0.6751 | val_acc=0.7210 | 13s\n",
      "Epoch 22/50 | train_loss=0.6489 | val_acc=0.7125 | 13s\n",
      "Epoch 23/50 | train_loss=0.6318 | val_acc=0.7430 | 13s\n",
      "Epoch 24/50 | train_loss=0.6275 | val_acc=0.7400 | 13s\n",
      "Epoch 25/50 | train_loss=0.6073 | val_acc=0.7320 | 13s\n",
      "Epoch 26/50 | train_loss=0.5895 | val_acc=0.7325 | 13s\n",
      "Epoch 27/50 | train_loss=0.5916 | val_acc=0.7420 | 12s\n",
      "Epoch 28/50 | train_loss=0.5721 | val_acc=0.7295 | 13s\n",
      "Epoch 29/50 | train_loss=0.5357 | val_acc=0.7235 | 13s\n",
      "Epoch 30/50 | train_loss=0.5354 | val_acc=0.7390 | 13s\n",
      "Epoch 31/50 | train_loss=0.5445 | val_acc=0.7330 | 12s\n",
      "Epoch 32/50 | train_loss=0.5223 | val_acc=0.7325 | 13s\n",
      "Epoch 33/50 | train_loss=0.5035 | val_acc=0.7455 | 13s\n",
      "Epoch 34/50 | train_loss=0.5179 | val_acc=0.7470 | 15s\n",
      "Epoch 35/50 | train_loss=0.5031 | val_acc=0.7495 | 15s\n",
      "Epoch 36/50 | train_loss=0.4906 | val_acc=0.7355 | 14s\n",
      "Epoch 37/50 | train_loss=0.4812 | val_acc=0.7495 | 12s\n",
      "Epoch 38/50 | train_loss=0.4660 | val_acc=0.7575 | 13s\n",
      "Epoch 39/50 | train_loss=0.4620 | val_acc=0.7560 | 13s\n",
      "Epoch 40/50 | train_loss=0.4554 | val_acc=0.7515 | 13s\n",
      "Epoch 41/50 | train_loss=0.4473 | val_acc=0.7430 | 13s\n",
      "Epoch 42/50 | train_loss=0.4364 | val_acc=0.7430 | 12s\n",
      "Epoch 43/50 | train_loss=0.4353 | val_acc=0.7465 | 13s\n",
      "Epoch 44/50 | train_loss=0.4488 | val_acc=0.7525 | 13s\n",
      "Epoch 45/50 | train_loss=0.4179 | val_acc=0.7585 | 12s\n",
      "Epoch 46/50 | train_loss=0.4178 | val_acc=0.7465 | 13s\n",
      "Epoch 47/50 | train_loss=0.4031 | val_acc=0.7435 | 13s\n",
      "Epoch 48/50 | train_loss=0.4089 | val_acc=0.7345 | 12s\n",
      "Epoch 49/50 | train_loss=0.4135 | val_acc=0.7425 | 13s\n",
      "Epoch 50/50 | train_loss=0.3948 | val_acc=0.7405 | 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21000\\2341484527.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val_acc(saved)=0.7585 | Reloaded val_acc=0.7585\n",
      "Weights saved: best -> simplecnn32_best.pth, last -> simplecnn32_last.pth\n",
      "SimpleCNN: acc=0.7585\n",
      "Per-class accuracy:\n",
      "  class 0: 0.8182\n",
      "  class 1: 0.8677\n",
      "  class 2: 0.6318\n",
      "  class 3: 0.6364\n",
      "  class 4: 0.7293\n",
      "  class 5: 0.6859\n",
      "  class 6: 0.7700\n",
      "  class 7: 0.8097\n",
      "  class 8: 0.8079\n",
      "  class 9: 0.8199\n"
     ]
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*4*4, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "EPOCHS = 50\n",
    "model_simple = SimpleCNN(num_classes=NUM_CLASSES)\n",
    "path_simple_best, path_simple_last, acc_simple, pc_simple = fit_model(\n",
    "    model_simple, train_ld_32, test_ld_32,\n",
    "    epochs=EPOCHS, lr=1e-3, device=DEVICE,\n",
    "    name='simplecnn32', num_classes=NUM_CLASSES\n",
    ")\n",
    "print(f'SimpleCNN: acc={acc_simple:.4f}')\n",
    "print('Per-class accuracy:')\n",
    "for i, v in enumerate(pc_simple):\n",
    "    print(f'  class {i}: {v:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f79e64",
   "metadata": {},
   "source": [
    "Собираем resnet18, адаптированный под 32×32 (уменьшаем первый слой до 3×3 stride 1, убираем maxpool, меняем fc на 10 классов), и обучаем модель напрямую на изображениях. Сохраняем лучшие веса и печатаем метрики по классам\n",
    "\n",
    "Resnet'у нужно на те же 50 эпох уже около полутора часов, поэтому его лучше не обучать заново, просто подгрузить через pickle уже полученные веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fea17b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | train_loss=1.7947 | val_acc=0.3850 | 102s\n",
      "Epoch 2/50 | train_loss=1.4689 | val_acc=0.4785 | 97s\n",
      "Epoch 3/50 | train_loss=1.2759 | val_acc=0.5135 | 97s\n",
      "Epoch 4/50 | train_loss=1.1419 | val_acc=0.5480 | 97s\n",
      "Epoch 5/50 | train_loss=1.0282 | val_acc=0.6050 | 98s\n",
      "Epoch 6/50 | train_loss=0.9497 | val_acc=0.5585 | 102s\n",
      "Epoch 7/50 | train_loss=0.8804 | val_acc=0.6540 | 104s\n",
      "Epoch 8/50 | train_loss=0.8077 | val_acc=0.6465 | 112s\n",
      "Epoch 9/50 | train_loss=0.7632 | val_acc=0.6995 | 210s\n",
      "Epoch 10/50 | train_loss=0.7050 | val_acc=0.7035 | 110s\n",
      "Epoch 11/50 | train_loss=0.6586 | val_acc=0.7195 | 110s\n",
      "Epoch 12/50 | train_loss=0.6056 | val_acc=0.7415 | 189s\n",
      "Epoch 13/50 | train_loss=0.5903 | val_acc=0.7195 | 194s\n",
      "Epoch 14/50 | train_loss=0.5397 | val_acc=0.7390 | 208s\n",
      "Epoch 15/50 | train_loss=0.5342 | val_acc=0.7305 | 103s\n",
      "Epoch 16/50 | train_loss=0.4784 | val_acc=0.7705 | 98s\n",
      "Epoch 17/50 | train_loss=0.4570 | val_acc=0.7395 | 98s\n",
      "Epoch 18/50 | train_loss=0.4227 | val_acc=0.7685 | 97s\n",
      "Epoch 19/50 | train_loss=0.4153 | val_acc=0.7395 | 97s\n",
      "Epoch 20/50 | train_loss=0.3922 | val_acc=0.7990 | 97s\n",
      "Epoch 21/50 | train_loss=0.3712 | val_acc=0.7580 | 97s\n",
      "Epoch 22/50 | train_loss=0.3600 | val_acc=0.7765 | 98s\n",
      "Epoch 23/50 | train_loss=0.3349 | val_acc=0.7815 | 182s\n",
      "Epoch 24/50 | train_loss=0.3159 | val_acc=0.7550 | 249s\n",
      "Epoch 25/50 | train_loss=0.3021 | val_acc=0.8090 | 195s\n",
      "Epoch 26/50 | train_loss=0.2836 | val_acc=0.7855 | 98s\n",
      "Epoch 27/50 | train_loss=0.2538 | val_acc=0.7815 | 98s\n",
      "Epoch 28/50 | train_loss=0.2504 | val_acc=0.7615 | 98s\n",
      "Epoch 29/50 | train_loss=0.2449 | val_acc=0.7920 | 99s\n",
      "Epoch 30/50 | train_loss=0.2148 | val_acc=0.8120 | 98s\n",
      "Epoch 31/50 | train_loss=0.1981 | val_acc=0.7775 | 98s\n",
      "Epoch 32/50 | train_loss=0.2000 | val_acc=0.8020 | 97s\n",
      "Epoch 33/50 | train_loss=0.2075 | val_acc=0.7825 | 97s\n",
      "Epoch 34/50 | train_loss=0.1789 | val_acc=0.8155 | 98s\n",
      "Epoch 35/50 | train_loss=0.1587 | val_acc=0.8095 | 103s\n",
      "Epoch 36/50 | train_loss=0.1790 | val_acc=0.7840 | 103s\n",
      "Epoch 37/50 | train_loss=0.1382 | val_acc=0.7915 | 99s\n",
      "Epoch 38/50 | train_loss=0.1550 | val_acc=0.7755 | 105s\n",
      "Epoch 39/50 | train_loss=0.1419 | val_acc=0.8095 | 99s\n",
      "Epoch 40/50 | train_loss=0.1215 | val_acc=0.7975 | 191s\n",
      "Epoch 41/50 | train_loss=0.1275 | val_acc=0.8145 | 244s\n",
      "Epoch 42/50 | train_loss=0.1266 | val_acc=0.7735 | 244s\n",
      "Epoch 43/50 | train_loss=0.1399 | val_acc=0.8180 | 246s\n",
      "Epoch 44/50 | train_loss=0.1025 | val_acc=0.8150 | 245s\n",
      "Epoch 45/50 | train_loss=0.1009 | val_acc=0.8215 | 134s\n",
      "Epoch 46/50 | train_loss=0.1020 | val_acc=0.8125 | 159s\n",
      "Epoch 47/50 | train_loss=0.0934 | val_acc=0.8305 | 98s\n",
      "Epoch 48/50 | train_loss=0.0933 | val_acc=0.8100 | 129s\n",
      "Epoch 49/50 | train_loss=0.1039 | val_acc=0.8120 | 138s\n",
      "Epoch 50/50 | train_loss=0.0877 | val_acc=0.8175 | 102s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21000\\2731837497.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val_acc(saved)=0.8305 | Reloaded val_acc=0.8305\n",
      "Weights saved: best -> resnet_best.pth, last -> resnet_last.pth\n",
      "ResNet: val_acc=0.8305\n",
      "Per-class accuracy:\n",
      "  class 0: 0.8770\n",
      "  class 1: 0.8730\n",
      "  class 2: 0.7562\n",
      "  class 3: 0.6667\n",
      "  class 4: 0.8232\n",
      "  class 5: 0.7644\n",
      "  class 6: 0.8263\n",
      "  class 7: 0.8805\n",
      "  class 8: 0.8768\n",
      "  class 9: 0.9479\n"
     ]
    }
   ],
   "source": [
    "def make_resnet(num_classes=10):\n",
    "    m = torchvision.models.resnet18(weights=None)\n",
    "    m.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    m.maxpool = nn.Identity()\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for images, targets in loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running += loss.item()\n",
    "    return running / max(1, len(loader))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, num_classes=10):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    per_class_correct = np.zeros(num_classes, dtype=np.int64)\n",
    "    per_class_total = np.zeros(num_classes, dtype=np.int64)\n",
    "    for images, targets in loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        logits = model(images)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "        t_np = targets.cpu().numpy()\n",
    "        p_np = preds.cpu().numpy()\n",
    "        for t, p in zip(t_np, p_np):\n",
    "            per_class_total[t] += 1\n",
    "            per_class_correct[t] += int(t == p)\n",
    "    acc = correct / max(1, total)\n",
    "    per_class_acc = (per_class_correct / np.maximum(1, per_class_total)).tolist()\n",
    "    return acc, per_class_acc\n",
    "\n",
    "def fit_model(model, train_loader, val_loader, epochs=5, lr=1e-3, device=torch.device('cpu'), name='model', num_classes=10):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    best_path = f'{name}_best.pth'\n",
    "    last_path = f'{name}_last.pth'\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        t0 = time.time()\n",
    "        tr_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_acc, _ = evaluate(model, val_loader, device, num_classes=num_classes)\n",
    "        dt = time.time() - t0\n",
    "        print(f'Epoch {epoch}/{epochs} | train_loss={tr_loss:.4f} | val_acc={val_acc:.4f} | {int(dt)}s')\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "        torch.save(model.state_dict(), last_path)\n",
    "\n",
    "    model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "    final_acc, per_class_acc = evaluate(model, val_loader, device, num_classes=num_classes)\n",
    "    print(f'Best val_acc(saved)={best_acc:.4f} | Reloaded val_acc={final_acc:.4f}')\n",
    "    print(f'Weights saved: best -> {best_path}, last -> {last_path}')\n",
    "    return best_path, last_path, final_acc, per_class_acc\n",
    "\n",
    "EPOCHS = 50\n",
    "model_resnet = make_resnet(num_classes=NUM_CLASSES)\n",
    "path_resnet_best, path_resnet_last, acc_resnet, pc_resnet = fit_model(\n",
    "    model_resnet, train_ld_32, test_ld_32,\n",
    "    epochs=EPOCHS, lr=1e-3, device=DEVICE,\n",
    "    name='resnet', num_classes=NUM_CLASSES\n",
    ")\n",
    "print(f'ResNet: val_acc={acc_resnet:.4f}')\n",
    "print('Per-class accuracy:')\n",
    "for i, v in enumerate(pc_resnet):\n",
    "    print(f'  class {i}: {v:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a7906b",
   "metadata": {},
   "source": [
    "После обучения cnn и resnet18 извлекаем эмбеддинги (последние скрытые представления до классификатора) на train и test, и сохраняем их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb1beab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21000\\739066402.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: embeddings_simplecnn_train.pkl, embeddings_simplecnn_test.pkl\n",
      "SimpleCNN shapes: (10000, 4096) (2000, 4096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21000\\739066402.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: embeddings_resnet_train.pkl, embeddings_resnet_test.pkl\n",
      "ResNet shapes: (10000, 512) (2000, 512)\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def extract_simplecnn_features(ckpt_path, train_loader, test_loader, num_classes=10, device=DEVICE):\n",
    "    model = SimpleCNN(num_classes=num_classes).to(device)\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    def run_loader(loader):\n",
    "        feats, labels = [], []\n",
    "        for images, targets in loader:\n",
    "            images = images.to(device)\n",
    "            # фичи до classifier: [B,256,4,4] -> [B,4096]\n",
    "            f = model.features(images)\n",
    "            f = torch.flatten(f, 1)\n",
    "            feats.append(f.cpu().numpy())\n",
    "            labels.append(targets.numpy())\n",
    "        X = np.concatenate(feats, axis=0)\n",
    "        y = np.concatenate(labels, axis=0)\n",
    "        return X, y\n",
    "\n",
    "    X_train, y_train = run_loader(train_loader)\n",
    "    X_test,  y_test  = run_loader(test_loader)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_resnet_features(ckpt_path, train_loader, test_loader, num_classes=10, device=DEVICE):\n",
    "    model = make_resnet(num_classes=num_classes).to(device)\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # обрезаем голову: всё до avgpool\n",
    "    feature_extractor = nn.Sequential(*(list(model.children())[:-1])).to(device).eval()\n",
    "\n",
    "    def run_loader(loader):\n",
    "        feats, labels = [], []\n",
    "        for images, targets in loader:\n",
    "            images = images.to(device)\n",
    "            f = feature_extractor(images)   # [B, 512, 1, 1]\n",
    "            f = torch.flatten(f, 1)         # [B, 512]\n",
    "            feats.append(f.cpu().numpy())\n",
    "            labels.append(targets.numpy())\n",
    "        X = np.concatenate(feats, axis=0)\n",
    "        y = np.concatenate(labels, axis=0)\n",
    "        return X, y\n",
    "\n",
    "    X_train, y_train = run_loader(train_loader)\n",
    "    X_test,  y_test  = run_loader(test_loader)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# извлекаем эмбеддинги\n",
    "Xtr_s, ytr_s, Xte_s, yte_s = extract_simplecnn_features(\n",
    "    path_simple_best, train_ld_32, test_ld_32, num_classes=NUM_CLASSES, device=DEVICE\n",
    ")\n",
    "with open('embeddings_simplecnn_train.pkl', 'wb') as f:\n",
    "    pickle.dump({'X': Xtr_s, 'y': ytr_s}, f)\n",
    "with open('embeddings_simplecnn_test.pkl', 'wb') as f:\n",
    "    pickle.dump({'X': Xte_s, 'y': yte_s}, f)\n",
    "print('Saved: embeddings_simplecnn_train.pkl, embeddings_simplecnn_test.pkl')\n",
    "print('SimpleCNN shapes:', Xtr_s.shape, Xte_s.shape)\n",
    "\n",
    "Xtr_r, ytr_r, Xte_r, yte_r = extract_resnet_features(\n",
    "    path_resnet_best, train_ld_32, test_ld_32, num_classes=NUM_CLASSES, device=DEVICE\n",
    ")\n",
    "with open('embeddings_resnet_train.pkl', 'wb') as f:\n",
    "    pickle.dump({'X': Xtr_r, 'y': ytr_r}, f)\n",
    "with open('embeddings_resnet_test.pkl', 'wb') as f:\n",
    "    pickle.dump({'X': Xte_r, 'y': yte_r}, f)\n",
    "print('Saved: embeddings_resnet_train.pkl, embeddings_resnet_test.pkl')\n",
    "print('ResNet shapes:', Xtr_r.shape, Xte_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a0d79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21000\\1791987209.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  simple_model.load_state_dict(torch.load(path_simple_best, map_location=DEVICE))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21000\\1791987209.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet_model.load_state_dict(torch.load(path_resnet_best, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DL baselines -> dl_baselines_metrics.json\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def predict_loader(model, loader, device):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device)\n",
    "        logits = model(images)\n",
    "        pred = logits.argmax(dim=1).cpu().numpy()\n",
    "        ys.append(targets.numpy())\n",
    "        ps.append(pred)\n",
    "    y_true = np.concatenate(ys)\n",
    "    y_pred = np.concatenate(ps)\n",
    "    return y_true, y_pred\n",
    "\n",
    "simple_model = SimpleCNN(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "simple_model.load_state_dict(torch.load(path_simple_best, map_location=DEVICE))\n",
    "y_true_s, y_pred_s = predict_loader(simple_model, test_ld_32, DEVICE)\n",
    "acc_s = accuracy_score(y_true_s, y_pred_s)\n",
    "p_s, r_s, f_s, _ = precision_recall_fscore_support(y_true_s, y_pred_s, average='macro', zero_division=0)\n",
    "\n",
    "resnet_model = make_resnet(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "resnet_model.load_state_dict(torch.load(path_resnet_best, map_location=DEVICE))\n",
    "y_true_r, y_pred_r = predict_loader(resnet_model, test_ld_32, DEVICE)\n",
    "acc_r = accuracy_score(y_true_r, y_pred_r)\n",
    "p_r, r_r, f_r, _ = precision_recall_fscore_support(y_true_r, y_pred_r, average='macro', zero_division=0)\n",
    "\n",
    "dl_metrics = {\n",
    "    'SimpleCNN': {\n",
    "        'accuracy': float(acc_s),\n",
    "        'precision_macro': float(p_s),\n",
    "        'recall_macro': float(r_s),\n",
    "        'f1_macro': float(f_s),\n",
    "    },\n",
    "    'ResNet': {\n",
    "        'accuracy': float(acc_r),\n",
    "        'precision_macro': float(p_r),\n",
    "        'recall_macro': float(r_r),\n",
    "        'f1_macro': float(f_r),\n",
    "    }\n",
    "}\n",
    "with open('dl_baselines_metrics.json', 'w') as f:\n",
    "    json.dump(dl_metrics, f)\n",
    "print('Saved DL baselines -> dl_baselines_metrics.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
